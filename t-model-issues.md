# Filtered Union Bibliography

This automatically-generated file contains references from the [main union bibliography](README.md) that have been filtered for a single tag.  Do not edit this file; instead, please update the main bibliography and tag references appropriately to have them show up here.  Thank you!

The papers are listed in the same order as the main bibliography; e.g., by year of publication / release; then by surname / name of the first author.

<p>
</p>
  
[![Model Issues](https://img.shields.io/badge/t-model%20issues-yellow)](t-model-issues.md)
* Nejadgholi, I., Kiritchenko, S., Fraser, K.C., Balkir, E. (2023) Concept-Based Explanations to Test for False Causal Relationships Learned by Abusive Language Classifiers. In Proceedings of the 7th Workshop on Online Abuse and Harms (WOAH), pages 138â€“149, Toronto, Canada. Association for Computational Linguistics. [[paper](https://aclanthology.org/2023.woah-1.14/)]  [![Biases](https://img.shields.io/badge/t-biases-pink)](t-biases.md) [![Model Issues](https://img.shields.io/badge/t-model%20issues-yellow)](t-model-issues.md) [![published](https://img.shields.io/badge/type-published-lightgrey)](type-published.md)  
* Nejadgholi, I., Balkir, E., Fraser, K.C., Kiritchenko, S. (2022) Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information.In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 225â€“237, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics. [[paper](https://aclanthology.org/2022.blackboxnlp-1.18/)] [![Biases](https://img.shields.io/badge/t-biases-pink)](t-biases.md) [![Model Issues](https://img.shields.io/badge/t-model%20issues-yellow)](t-model-issues.md) [![published](https://img.shields.io/badge/type-published-lightgrey)](type-published.md)
* Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?ðŸ¦œ. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [[paper](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)] ![Model Issues](https://img.shields.io/badge/t-model%20issues-yellow) ![Biases](https://img.shields.io/badge/t-biases-pink) ![published](https://img.shields.io/badge/type-published-lightgrey)
* Field, A., Blodgett, S. L., Talat, Z., & Tsvetkov, Y. (2021, August). A Survey of Race, Racism, and Anti-Racism in NLP. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1905â€“1925, Online. Association for Computational Linguistics. doi:10.18653/v1/2021.acl-long.149 [[paper](https://aclanthology.org/2021.acl-long.149/)] ![Model Issues](https://img.shields.io/badge/t-model%20issues-yellow) ![Biases](https://img.shields.io/badge/t-biases-pink) ![published](https://img.shields.io/badge/type-published-lightgrey)
* Floridi, L., Chiriatti, M. GPT-3: Its Nature, Scope, Limits, and Consequences. Minds & Machines 30, 681â€“694 (2020). https://doi.org/10.1007/s11023-020-09548-1 [[paper](https://link.springer.com/content/pdf/10.1007/s11023-020-09548-1.pdf)] ![Model Issues](https://img.shields.io/badge/t-model%20issues-yellow) ![published](https://img.shields.io/badge/type-published-lightgrey)
